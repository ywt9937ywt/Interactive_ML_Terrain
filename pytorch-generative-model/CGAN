import utils, torch, time, os, pickle
import cv2, imageio, io, random
import tifffile as tiff
import numpy as np
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import webdataset as wds
from itertools import islice, chain, cycle
from torch.autograd import grad
from torch.utils.data import Dataset, Sampler, DataLoader, IterableDataset
from torchvision import transforms
from typing import Iterator, Optional, Sized
from os.path import exists, join, isdir
from os import makedirs

class generator(nn.Module):
    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)
    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S
    def __init__(self, input_dim=100, output_dim=1, input_size=32):
        super(generator, self).__init__()
        self.embedding_class_n = 5
        self.embedding_dim = 5
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.input_size = input_size
        self.output_size = 128

        self.fc = nn.Sequential(
            nn.Linear(self.input_dim, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Linear(1024, 128 * (self.input_size // 8) * (self.input_size // 8)),
            nn.BatchNorm1d(128 * (self.input_size // 8) * (self.input_size // 8)),#128*16*16
            nn.ReLU(),
        )
        self.deconv = nn.Sequential(
            nn.ConvTranspose2d(256, 64, 4, 2, 1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.ConvTranspose2d(32, self.output_dim, 4, 2, 1),
            nn.Tanh(),
        )
        self.label_generator_process = nn.Sequential(
            nn.Embedding(self.embedding_class_n, self.embedding_dim),
            nn.Linear(self.embedding_dim, 16),
            nn.BatchNorm2d(self.output_size),
            nn.ReLU(),
            nn.Linear(16, 2),
        )
        utils.initialize_weights(self)

    def forward(self, input):
        noise_vector, sketch = input
        processed_sketch = self.label_generator_process(sketch)#128, 128, embedding_dim
        processed_sketch = processed_sketch.view(-1, 128, (self.input_size // 8), (self.input_size // 8))


        x = self.fc(noise_vector)
        x = x.view(-1, 128, (self.input_size // 8), (self.input_size // 8))
        # print(x.size())
        # print(processed_sketch.size())
        concat = torch.cat((x, processed_sketch), dim = 1)
        image = self.deconv(concat)
        return image
        return (x + 1)/2

class discriminator(nn.Module):
    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)
    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S
    def __init__(self, input_dim=1, output_dim=1, input_size=32):
        super(discriminator, self).__init__()
        self.embedding_class_n = 5
        self.embedding_dim = 5
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.input_size = input_size

        self.labelout_dim = 8

        self.conv = nn.Sequential(
            nn.Conv2d(self.input_dim + self.labelout_dim, 64, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
        )
        self.fc = nn.Sequential(
            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),
            nn.BatchNorm1d(1024),
            nn.LeakyReLU(0.2),
            nn.Linear(1024, self.output_dim),
            # nn.Sigmoid(),
        )
        self.label_dics_process = nn.Sequential(
            nn.Embedding(self.embedding_class_n, self.embedding_dim),
            nn.Linear(self.embedding_dim, 8)
        )
        utils.initialize_weights(self)

    def forward(self, input):
        img, label = input
        label_output = self.label_dics_process(label)
        label_output = label_output.view(-1, 8, 128, 128)
        # print(img.size())
        # print(label_output.size())
        img = img[:, None, :, :]
        concat = torch.cat((img, label_output), dim = 1)
        x = self.conv(concat)
        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))
        x = self.fc(x)
        return x

class CGAN(object):
    def __init__(self, config):
    #     self.dataset = wds.WebDataset(config.tar_paths[0]).decode("rgb").to_tuple("tif", "rs.png")
    #     for img, tif in self.dataset:
    #         print(img.shape)
    #         return
        # parameters
        self.config = config
        self.epoch = config.epoch
        self.sample_num = 1000
        self.batch_size = config.nimg_batch
        self.save_dir = join(config.root_path, config.save_dir)
        self.result_dir = join(config.root_path, config.result_dir)
        # self.log_dir = args.log_dir
        self.gpu_mode = config.gpu_mode
        self.model_name = config.gan_type
        self.input_size = config.input_size
        self.z_dim = 100
        self.c = 0.01                   # clipping value
        self.lambda_ = 10
        self.n_critic = 5               # the number of iterations of the critic per generator iteration

        self.dataset = WGANGP_dataset(self.config, self.config.tar_paths)
        self.data_loader = DataLoader(self.dataset,
                                      batch_size= self.batch_size,
                                      collate_fn=WGAN_Collate, 
                                    #   sampler = training_sampler,
                                    #   batch_sampler=training_batch_sampler
                                      )
        # for sample in self.data_loader:
        #     print(sample[0].shape)
        #     print(sample[1].shape)
        #     return
        # data = next(iter(self.dataset))
        # print(data[0].shape)
        # print(data[1].shape)
        # return
        # networks init
        self.G = generator(input_dim=self.z_dim, output_dim=1, input_size=self.input_size)
        self.D = discriminator(input_dim=1, output_dim=1, input_size=self.input_size)
        # a = torch.Tensor(np.zeros((2, 128, 128)))
        # b = torch.LongTensor(np.zeros((2,128, 128)))6+
        # print(a.size())
        # print(b.size())
        # x = self.D((a,b))
        # print(x.size())
        # return
        # self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)
        # self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)
        self.G_optimizer = optim.Adam(self.G.parameters(), lr=config.lrG, betas=(config.beta1, config.beta2))
        self.D_optimizer = optim.Adam(self.D.parameters(), lr=config.lrD, betas=(config.beta1, config.beta2))

        if self.gpu_mode:
            self.G.cuda()
            self.D.cuda()
            self.BCE_loss = nn.BCELoss().cuda()
        else:
            self.BCE_loss = nn.BCELoss()

        print('---------- Networks architecture -------------')
        utils.print_network(self.G)
        utils.print_network(self.D)
        print('-----------------------------------------------')

        # fixed noise
        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))
        if self.gpu_mode:
            self.sample_z_ = self.sample_z_.cuda()

    def train(self):

        self.train_hist = {}
        self.meanval = []
        self.minval = []
        self.maxval = []
        self.train_hist['D_loss'] = []
        self.train_hist['G_loss'] = []
        self.train_hist['per_epoch_time'] = []
        self.train_hist['total_time'] = []

        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)
        if self.gpu_mode:
            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()

        self.D.train()
        print('training start!!')
        start_time = time.time()
        for epoch in range(self.epoch):
            self.G.train()
            epoch_start_time = time.time()
            count = 0
            for sample_batch in self.data_loader:
                # if iter == self.data_loader.dataset.__len__() // self.batch_size:
                #     break
                tifs = sample_batch[0]
                sketches = sample_batch[1]

                tifs = torch.LongTensor(np.zeros((self.batch_size,128,128)))
                sketches = torch.LongTensor(np.zeros((self.batch_size,128,128)))
                user_input_sketch = torch.LongTensor(np.zeros((self.batch_size,128,128)))

                z_ = torch.rand((self.batch_size, self.z_dim))
                z_ = torch.rand((self.batch_size, self.z_dim))
                if self.gpu_mode:
                    z_, sketches, tifs, user_input_sketch = z_.cuda(), sketches.cuda(), tifs.cuda(), user_input_sketch.cuda()

                gen_input = (z_, sketches)
                disc_input = (tifs, sketches)

                # update D network
                self.D_optimizer.zero_grad()

                D_real = self.D(disc_input)
                # D_real_loss = torch.mean(D_real)
                D_real_loss = self.BCE_loss(D_real, self.y_real_)

                G_ = torch.squeeze(self.G(gen_input))
                D_fake = self.D((G_, user_input_sketch))
                # D_fake_loss = torch.mean(D_fake)
                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)

                D_loss = D_real_loss + D_fake_loss
                self.train_hist['D_loss'].append(D_loss.item())

                D_loss.backward()
                self.D_optimizer.step()

                # update G network
                self.G_optimizer.zero_grad()

                G_ = torch.squeeze(self.G(gen_input))
                D_fake = self.D((G_, user_input_sketch))
                G_loss = self.BCE_loss(D_fake, self.y_real_)
                self.train_hist['G_loss'].append(G_loss.item())

                G_loss.backward()
                self.G_optimizer.step()
                #### following are WGAN_GP implementation
                # # gradient penalty
                # alpha = torch.rand((self.batch_size, 1, 1, 1))

                # if self.gpu_mode:
                #     alpha = alpha.cuda()

                # x_hat = alpha * x_.data + (1 - alpha) * G_.data
                # x_hat.requires_grad = True

                # pred_hat = self.D(x_hat.float())
                # if self.gpu_mode:
                #     gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).cuda(),
                #                  create_graph=True, retain_graph=True, only_inputs=True)[0]
                # else:
                #     gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()),
                #                      create_graph=True, retain_graph=True, only_inputs=True)[0]

                # gradient_penalty = self.lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()

                # D_loss = -D_real_loss + D_fake_loss + gradient_penalty

                # D_loss.backward()
                # self.D_optimizer.step()

                # # clipping D
                # # for p in self.D.parameters():
                # #     p.data.clamp_(-self.c, self.c)

                # if ((iter+1) % self.n_critic) == 0:
                #     # update G network
                #     self.G_optimizer.zero_grad()

                #     G_ = self.G(z_)
                #     D_fake = self.D(G_)
                #     G_loss = -torch.mean(D_fake)
                #     self.train_hist['G_loss'].append(G_loss.item())

                #     G_loss.backward()
                #     self.G_optimizer.step()

                #     self.train_hist['D_loss'].append(D_loss.item())
                ######
                count = count + 1
                if ((iter + 1) % 100) == 0:
                    print("Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f" %
                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))
                return
                
            # print("count {0}".format(count))
            self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)
            if epoch % 3 == 0:
                with torch.no_grad():
                    self.visualize_results((epoch+1))

        self.train_hist['total_time'].append(time.time() - start_time)
        print("Avg one epoch time: %.2f, total %d epochs time: %.2f" % (np.mean(self.train_hist['per_epoch_time']),
              self.epoch, self.train_hist['total_time'][0]))
        print("Training finish!... save training results")

        self.save()
        utils.generate_animation(self.result_dir + '/' + self.model_name,
                                 self.epoch)
        # utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.model_name), self.model_name)

        r = range(self.epoch)
        plt.title('val')
        plt.plot(r, self.meanval, 'r-')
        plt.plot(r, self.maxval, 'b-')
        plt.plot(r, self.minval, 'g-')
        plt.show()

    def visualize_results(self, epoch, fix=True):
        self.G.eval()

        if not os.path.exists(self.result_dir + '/' + self.model_name):
            os.makedirs(self.result_dir + '/' + self.model_name)

        tot_num_samples = min(self.sample_num, self.batch_size)
        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))

        if fix:
            """ fixed noise """
            samples = self.G(self.sample_z_)
        else:
            """ random noise """
            sample_z_ = torch.rand((self.batch_size, self.z_dim))
            if self.gpu_mode:
                sample_z_ = sample_z_.cuda()

            samples = self.G(sample_z_)

        if self.gpu_mode:
            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)
        else:
            samples = samples.data.numpy().transpose(0, 2, 3, 1)

        # samples = (samples + 1) / 2
        self.firsttime = True
        img = np.squeeze(samples[0])
        # self.plt_image = img
        self.meanval.append(np.mean(img))
        self.minval.append(np.min(img))
        self.maxval.append(np.max(img))
        utils.save_images(samples[0], [image_frame_dim, image_frame_dim],
                          self.result_dir + '/' + self.model_name + '_epoch%03d' % epoch + '.png')

    def update(self, frame):
        plt.cla()
        plt.plot(self.plt_image)

    def save(self):
        save_dir = os.path.join(self.save_dir, self.model_name)

        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + '_G.pkl'))
        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + '_D.pkl'))

        with open(os.path.join(save_dir, self.model_name + '_history.pkl'), 'wb') as f:
            pickle.dump(self.train_hist, f)

    def load(self):
        save_dir = os.path.join(self.save_dir, self.model_name)

        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_G.pkl')))
        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_D.pkl')))



class WGANGP_dataset(IterableDataset):
    def __init__(self, config, urls, mode='train'):
        print("--------Initialize WGAN_GP dataset --------")
        self.config = config
        #self.filename_list = ['pre_128.npy']
        # self.convert(self.filename_list[0])
        # self.convert(self.config.dataset_subpath[0])
        self.dataset_seg = [0.8, 0.1, 0.1]
        self.mode = mode
        self.urls = urls
        # self.transform = transforms.Compose([transforms.ToTensor()])
        # load converted data
        
        print("--------Initializing WGAN dataset finished--------")

    # def process_data(self, url):
    #     dataset = wds.WebDataset(url).shuffle(1000).decode(
    #         wds.handle_extension("tif", wdsDecoder),
    #         wds.handle_extension("rs.png", wdsDecoder),
    #     ).to_tuple("tif", "rs.png")
    #     for sample in dataset:
    #         yield sample

    # def shuffled_data_list(self):
    #     return random

    # def get_stream(self, urlList):
    #     return chain.from_iterable(map(self.process_data, cycle(urlList)))

    # def get_streams(self):
    #     return zip(*[self.get_stream(self.urls) for _ in range(3)])
    
    def __iter__(self):
        for url in cycle(self.urls):
            dataset = wds.WebDataset(url).shuffle(1000).decode(
                "rgb"
            ).to_tuple("tif", "rs.png")
            for sample in dataset:
                yield sample

def wdsDecoder(value):
    return imageio.imread(io.BytesIO(value))

def WGAN_Collate(batch_data):
    # print(np.expand_dims(batch_data, axis=1).shape)
    # return torch.from_numpy(np.expand_dims(batch_data, axis=1))
    tifbatch = []
    rsbatch = []
    for t in batch_data:
        tifbatch.append(t[0])
        rsbatch.append(t[1])
    tifbatch = np.array(tifbatch)
    rsbatch = np.array(rsbatch)
    # print(tifbatch.shape)
    # print(rsbatch.shape)
    return (torch.from_numpy(tifbatch).int(), torch.from_numpy(rsbatch).int())

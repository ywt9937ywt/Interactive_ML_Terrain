import utils, torch, time, os, pickle
import cv2, imageio, io, random, torch, rioxarray
import tifffile as tiff
import numpy as np
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import webdataset as wds
from itertools import islice, chain, cycle
from torch.autograd import grad
from torch.utils.data import Dataset, Sampler, DataLoader, IterableDataset
from torchvision import transforms
from typing import Iterator, Optional, Sized
from os.path import exists, join, isdir
from os import makedirs

class generator(nn.Module):
    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)
    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S
    def __init__(self, input_dim=100, output_dim=1, input_size=32):
        super(generator, self).__init__()
        self.embedding_class_n = 20000
        self.embedding_dim = 30
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.input_size = input_size
        self.output_size = 128


        self.fc = nn.Sequential(
            nn.Linear(self.input_dim, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Linear(1024, 128 * (self.input_size // 8) * (self.input_size // 8)),
            nn.BatchNorm1d(128 * (self.input_size // 8) * (self.input_size // 8)),#128*16*16
            nn.ReLU(),
        )
        self.deconv = nn.Sequential(
            nn.ConvTranspose2d(256, 64, 4, 2, 1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.ConvTranspose2d(32, self.output_dim, 4, 2, 1),
            nn.Tanh(),
        )
        self.label_generator_process = nn.Sequential(
            nn.Embedding(self.embedding_class_n, self.embedding_dim),
            nn.Linear(self.embedding_dim, 16),
            nn.BatchNorm2d(self.output_size),
            nn.ReLU(),
            nn.Linear(16, 2),
        )
        utils.initialize_weights(self)

    def forward(self, input):
        noise_vector, sketch = input
        processed_sketch = self.label_generator_process(sketch.int())#128, 128, embedding_dim
        # print(processed_sketch.size())
        processed_sketch = processed_sketch.view(-1, 128, (self.input_size // 8), (self.input_size // 8))

        x = self.fc(noise_vector)
        x = x.view(-1, 128, (self.input_size // 8), (self.input_size // 8))
        # print(x.size())
        # print(processed_sketch.size())
        concat = torch.cat((x, processed_sketch), dim = 1)
        image = self.deconv(concat)
        return image

class discriminator(nn.Module):
    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)
    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S
    def __init__(self, input_dim=1, output_dim=1, input_size=32):
        super(discriminator, self).__init__()
        self.embedding_class_n = 20000
        self.embedding_dim = 30
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.input_size = input_size

        self.labelout_dim = 8

        self.conv = nn.Sequential(
            nn.Conv2d(2, 64, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
        )
        self.fc = nn.Sequential(
            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),
            nn.BatchNorm1d(1024),
            nn.LeakyReLU(0.2),
            nn.Linear(1024, self.output_dim),
            nn.Sigmoid(),
        )
        self.label_dics_process = nn.Sequential(
            nn.Embedding(self.embedding_class_n, self.embedding_dim),
            nn.Linear(self.embedding_dim, 8)
        )
        utils.initialize_weights(self)

    def forward(self, input):
        concat = input
        x = self.conv(concat)
        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))
        x = self.fc(x)
        return x

class CGAN(object):
    def __init__(self, config):
        self.config = config
        self.epoch = config.epoch
        self.batch_size = config.nimg_batch
        self.save_dir = join(config.root_path, config.save_dir)
        self.result_dir = join(config.root_path, config.result_dir)
        self.lossfunc = config.lossfun
        # self.test_sketch = cv2.imread("E:\\terrain_project\\usgs_terrain\\tiff_file\\us_patch128\\00000rs.png",0)
        # self.test_sketch = torch.LongTensor(self.test_sketch)


        # self.log_dir = args.log_dir
        self.gpu_mode = config.gpu_mode
        self.model_name = config.gan_type
        self.input_size = config.input_size
        self.z_dim = 100
        self.c = 0.01                   # clipping value
        self.lambda_ = 10
        self.n_critic = 5               # the number of iterations of the critic per generator iteration

        self.test_sketch = []
        for i in range(self.batch_size):
            pertest_sketch = cv2.imread("E:\\terrain_project\\usgs_terrain\\tiff_file\\us_patch128\\{0}rs.png".format(str(i).zfill(5)),0)
            self.test_sketch.append(pertest_sketch)
        self.test_sketch = torch.LongTensor(np.array(self.test_sketch))

        self.train_hist = {}
        self.meanval = []
        self.minval = []
        self.maxval = []
        self.train_hist['D_loss'] = []
        self.train_hist['G_loss'] = []
        self.train_hist['per_epoch_time'] = []
        self.train_hist['total_time'] = []

        self.dataset = CGAN_dataset(self.config, self.config.tar_paths)
        self.data_loader = DataLoader(self.dataset,
                                      batch_size= self.batch_size * 2,
                                      collate_fn=CGAN_Collate, 
                                      )
        self.G = generator(input_dim=self.z_dim, output_dim=1, input_size=self.input_size)
        self.D = discriminator(input_dim=1, output_dim=1, input_size=self.input_size)
        
        self.G_optimizer = optim.Adam(self.G.parameters(), lr=config.lrG, betas=(config.beta1, config.beta2))
        self.D_optimizer = optim.Adam(self.D.parameters(), lr=config.lrD, betas=(config.beta1, config.beta2))

        if self.gpu_mode:
            self.G.cuda()
            self.D.cuda()
            self.BCE_loss = nn.BCELoss().cuda()
        else:
            self.BCE_loss = nn.BCELoss()

        print('---------- Networks architecture -------------')
        utils.print_network(self.G)
        utils.print_network(self.D)
        print('-----------------------------------------------')

        

    def train(self):
        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)
        if self.gpu_mode:
            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()

        self.D.train()
        print('training start!!')
        start_time = time.time()
        for epoch in range(self.epoch):
            print("current epoch: {0}".format(epoch))
            self.G.train()
            epoch_start_time = time.time()
            stepcount = 0
            for sample_batch in self.data_loader:
                if stepcount == 250: break
                tifs = torch.squeeze(sample_batch[0][0:self.batch_size]).float()
                dis_sketches = torch.squeeze(sample_batch[1][0:self.batch_size]).float()
                gen_sketches = torch.squeeze(sample_batch[1][self.batch_size:]).float()

                z_ = torch.rand((self.batch_size, self.z_dim))
                if self.gpu_mode:
                    z_, dis_sketches, tifs, gen_sketches = z_.cuda(), dis_sketches.cuda(), tifs.cuda(), gen_sketches.cuda()

                gen_input = (z_, gen_sketches)

                disc_input = torch.cat((tifs[:, None, :, :], dis_sketches[:, None, :, :]), dim = 1)

                # update D network
                self.D_optimizer.zero_grad()

                if self.lossfunc == 'gan_loss':
                    D_real = self.D(disc_input)
                    # D_real_loss = torch.mean(D_real)
                    D_real_loss = self.BCE_loss(D_real, self.y_real_)

                    G_ = torch.squeeze(self.G(gen_input))

                    D_fake = self.D(torch.cat((G_[:, None, :, :], gen_sketches[:, None, :, :]), dim = 1))
                    # D_fake_loss = torch.mean(D_fake)
                    D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)

                    D_loss = D_real_loss + D_fake_loss
                    self.train_hist['D_loss'].append(D_loss.item())

                    D_loss.backward()
                    self.D_optimizer.step()

                    # update G network
                    self.G_optimizer.zero_grad()

                    G_ = torch.squeeze(self.G(gen_input))
                    D_fake = self.D(torch.cat((G_[:, None, :, :], gen_sketches[:, None, :, :]), dim = 1))
                    G_loss = self.BCE_loss(D_fake, self.y_real_)
                    self.train_hist['G_loss'].append(G_loss.item())

                    G_loss.backward()
                    self.G_optimizer.step()
                    return
                
                if self.lossfunc == 'wgan-gp_loss':
                    # cancat = torch.cat((tifs[:, None, :, :], dis_sketches[:, None, :, :]), dim = 1)
                    D_real = self.D(disc_input)
                    D_real_loss = torch.mean(D_real)

                    G_ = self.G(gen_input)
                    G_ = torch.squeeze(self.G(gen_input))
                    D_fake = self.D(torch.cat((G_[:, None, :, :], gen_sketches[:, None, :, :]), dim = 1))
                    D_fake_loss = torch.mean(D_fake)

                    alpha = torch.rand((self.batch_size, 1, 1, 1))
                    if self.gpu_mode:
                        alpha = alpha.cuda()

                    g_data = torch.cat((G_[:, None, :, :], gen_sketches[:, None, :, :]), dim = 1)
                    x_hat = alpha * disc_input.data + (1 - alpha) * g_data.data
                    x_hat.requires_grad = True

                    pred_hat = self.D(x_hat.float())

                    if self.gpu_mode:
                        gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).cuda(),
                                    create_graph=True, retain_graph=True, only_inputs=True)[0]
                    else:
                        gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()),
                                     create_graph=True, retain_graph=True, only_inputs=True)[0]

                    gradient_penalty = self.lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()
                    D_loss = -D_real_loss + D_fake_loss + gradient_penalty

                    D_loss.backward()
                    self.D_optimizer.step()

                    if ((stepcount+1) % self.n_critic) == 0:
                        # update G network
                        self.G_optimizer.zero_grad()

                        G_ = self.G(gen_input)
                        G_ = torch.squeeze(self.G(gen_input))
                        D_fake = self.D(torch.cat((G_[:, None, :, :], gen_sketches[:, None, :, :]), dim = 1))
                        G_loss = -torch.mean(D_fake)
                        self.train_hist['G_loss'].append(G_loss.item())

                        G_loss.backward()
                        self.G_optimizer.step()

                        self.train_hist['D_loss'].append(D_loss.item())
                #### following are WGAN_GP implementation
                # # gradient penalty
                # alpha = torch.rand((self.batch_size, 1, 1, 1))

                # if self.gpu_mode:
                #     alpha = alpha.cuda()

                # x_hat = alpha * x_.data + (1 - alpha) * G_.data
                # x_hat.requires_grad = True

                # pred_hat = self.D(x_hat.float())
                # if self.gpu_mode:
                #     gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).cuda(),
                #                  create_graph=True, retain_graph=True, only_inputs=True)[0]
                # else:
                #     gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()),
                #                      create_graph=True, retain_graph=True, only_inputs=True)[0]

                # gradient_penalty = self.lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()

                # D_loss = -D_real_loss + D_fake_loss + gradient_penalty

                # D_loss.backward()
                # self.D_optimizer.step()

                # # clipping D
                # # for p in self.D.parameters():
                # #     p.data.clamp_(-self.c, self.c)

                # if ((iter+1) % self.n_critic) == 0:
                #     # update G network
                #     self.G_optimizer.zero_grad()

                #     G_ = self.G(z_)
                #     D_fake = self.D(G_)
                #     G_loss = -torch.mean(D_fake)
                #     self.train_hist['G_loss'].append(G_loss.item())

                #     G_loss.backward()
                #     self.G_optimizer.step()

                #     self.train_hist['D_loss'].append(D_loss.item())
                ######
                stepcount = stepcount + 1
                if(stepcount % 100 == 0):
                    print("current step count: {0}".format(stepcount))

            # if (epoch % 100) == 0:
            print("Epoch: [%2d] D_loss: %.8f, G_loss: %.8f" %
                    ((epoch + 1),  D_loss.item(), G_loss.item()))
                
            # print("count {0}".format(count))
            self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)
            if epoch % 3 == 0:
                with torch.no_grad():
                    self.visualize_results((epoch+1))

        self.train_hist['total_time'].append(time.time() - start_time)
        print("Avg one epoch time: %.2f, total %d epochs time: %.2f" % (np.mean(self.train_hist['per_epoch_time']),
              self.epoch, self.train_hist['total_time'][0]))
        print("Training finish!... save training results")

        # self.save()
        # utils.generate_animation(self.result_dir + '/' + self.model_name,
                                #  self.epoch)
        # utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.model_name), self.model_name)

        # r = range(self.epoch)
        # plt.title('val')
        # plt.plot(r, self.meanval, 'r-')
        # plt.plot(r, self.maxval, 'b-')
        # plt.plot(r, self.minval, 'g-')
        # plt.show()

    def visualize_results(self, epoch, fix=True):
        self.G.eval()

        if not os.path.exists(self.result_dir + '/' + self.model_name):
            os.makedirs(self.result_dir + '/' + self.model_name)

        tot_num_samples = min(10, self.batch_size)
        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))

        # fixed noise
        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))
        # self.sample_z_ = torch.LongTensor(self.sample_z_)
        # print(self.sample_z_.size())
        # print(self.test_sketch.size())
        # if fix:
        #     """ fixed noise """
        #     samples = self.G((self.sample_z_, self.test_sketch))
        # else:
        #     """ random noise """
        #     # sample_z_ = torch.rand((self.batch_size, self.z_dim))

        if self.gpu_mode:
            self.sample_z_ = self.sample_z_.cuda()
            self.test_sketch = self.test_sketch.cuda()

        samples = self.G((self.sample_z_,self.test_sketch))

        if self.gpu_mode:
            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)
        else:
            samples = samples.data.numpy().transpose(0, 2, 3, 1)

        # samples = (samples + 1) / 2
        self.firsttime = True
        img = np.squeeze(samples[0])
        # self.plt_image = img
        self.meanval.append(np.mean(img))
        self.minval.append(np.min(img))
        self.maxval.append(np.max(img))
        utils.save_images(samples[0], [image_frame_dim, image_frame_dim],
                          self.result_dir + '/' + self.model_name + '//epoch%03d' % epoch + '.tif')

    def update(self, frame):
        plt.cla()
        plt.plot(self.plt_image)

    def save(self):
        save_dir = os.path.join(self.save_dir, self.model_name)

        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + '_G.pkl'))
        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + '_D.pkl'))

        with open(os.path.join(save_dir, self.model_name + '_history.pkl'), 'wb') as f:
            pickle.dump(self.train_hist, f)

    def load(self):
        save_dir = os.path.join(self.save_dir, self.model_name)

        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_G.pkl')))
        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_D.pkl')))


class CGAN_dataset(IterableDataset):
    def __init__(self, config, urls, mode='train'):
        print("--------Initialize WGAN_GP dataset --------")
        self.config = config
        self.dataset_seg = [0.8, 0.1, 0.1]
        self.mode = mode
        self.urls = urls
        
        print("--------Initializing WGAN dataset finished--------")
    
    def __iter__(self):
        for url in cycle(self.urls):
            dataset = wds.WebDataset(url).shuffle(1000).decode(
                wds.imagehandler("l8", "rs.png"),
                wds.handle_extension("tif", tif_decoder),
            ).to_tuple("tif", "rs.png")
            for sample in dataset:
                yield sample

def tif_decoder(value):
  return rioxarray.open_rasterio(io.BytesIO(value)).values

def CGAN_Collate(batch_data):
    tifbatch = []
    rsbatch = []
    for t in batch_data:
        tifbatch.append(t[0])
        rsbatch.append(t[1])
    tifbatch = np.array(tifbatch)
    rsbatch = np.array(rsbatch)
    return (torch.from_numpy(tifbatch).int(), torch.from_numpy(rsbatch).int())
